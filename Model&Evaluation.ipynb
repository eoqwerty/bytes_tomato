{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40abca3-9408-4381-95c1-a57450615f38",
   "metadata": {},
   "source": [
    "# Part 2: Model Build and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a502d3-91c0-44f0-91a6-d681c32f862d",
   "metadata": {},
   "source": [
    "This notebook is structured to help guide you through the second half of this challenge. If additional cells are needed to build and train your classifier, please feel free to use additional cells. Otherwise please refrain from adding cells at any point in the notebook during this challenge. Please also do not delete or modify the provided headers to the cells. You are welcome to additional comments, though, if needed! Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d230d5-5c42-4408-8151-709baf34a860",
   "metadata": {},
   "source": [
    "### Import your libraries in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0a7d24-33fd-49c6-af0a-76929a7d978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/giguser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e6b21-5a72-47da-bd04-d61a29b81b8d",
   "metadata": {},
   "source": [
    "### Import in your csv from the previous notebook in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbba31d-503b-4976-8537-980a6bf129e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', index_col='Unnamed: 0')\n",
    "test_df = pd.read_csv('test.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8953a2-4891-4b6f-a697-9ad14175060b",
   "metadata": {},
   "source": [
    "### Build and Train your Classifier in this and the following cell(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e419cd07-7d89-4598-ba57-456b1a4f653b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "X_train = df.drop(columns =['Sentiment'])\n",
    "y_train = df.loc[:, 'Sentiment']\n",
    "\n",
    "X_test = df.drop(columns =['Sentiment'])\n",
    "y_test = df.loc[:, 'Sentiment']\n",
    "\n",
    "# remove stopwords \n",
    "stop = stopwords.words('english')\n",
    "X_train['Phrase'] = X_train['Phrase'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# text vectorization:  transform our data into vectors\n",
    "# UNIGRAM\n",
    "uni_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "uni_vectorizer.fit(X_train['Phrase'])\n",
    "uni_X = uni_vectorizer.transform(X_train['Phrase']) \n",
    "uni_test_X =  uni_vectorizer.transform(X_test['Phrase'])\n",
    "\n",
    "#tf-itf, term frequency inverse term frequency:\n",
    "#UNIGRAM TF-ITF\n",
    "uni_tfitf = TfidfTransformer().fit(uni_X)\n",
    "uni_tf_X = uni_tfitf.transform(uni_X)\n",
    "uni_test_tf_X = uni_tfitf.transform(uni_test_X)\n",
    "\n",
    "# BIGRAM\n",
    "bi_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "bi_vectorizer.fit(X_train['Phrase'])\n",
    "bi_X = bi_vectorizer.transform(X_train['Phrase']) \n",
    "bi_test_X = bi_vectorizer.transform(X_test['Phrase']) \n",
    "\n",
    "#BIGRAM TF-ITF\n",
    "bi_tfitf = TfidfTransformer().fit(bi_X)\n",
    "bi_tf_X = bi_tfitf.transform(bi_X)\n",
    "bi_test_tf_X = bi_tfitf.transform(bi_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8930065c-940f-416a-8749-725e04f00010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.75, stratify=y)\n",
    "    \n",
    "    #clf = RandomForestClassifier(max_depth=2).fit(X_train, y_train)\n",
    "    #clf = SGDClassifier().fit(X_train, y_train)    \n",
    "    \n",
    "    # fine tune here\n",
    "    parameters = {'max_iter':[50, 100, 1000, 5000]}\n",
    "    sgd = SGDClassifier()\n",
    "    clf = GridSearchCV(sgd, parameters, scoring='f1_macro')\n",
    "\n",
    "    #parameters = {'max_depth':[1, 2, 3]}\n",
    "    #rfc = RandomForestClassifier()\n",
    "    #clf = GridSearchCV(rfc, parameters, scoring='f1_macro')\n",
    "    \n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    fclf = clf.best_estimator_\n",
    "    print('best params ', clf.best_params_)\n",
    "    \n",
    "    y_valid_pred = fclf.predict(X_valid)\n",
    "    print('Classification report ', classification_report(y_valid_pred, y_valid, zero_division=1))\n",
    "\n",
    "    print('Accuracy score: ', accuracy_score(y_valid, y_valid_pred))\n",
    "    print('F1 macro score: ', f1_score(y_valid, y_valid_pred, average='macro', zero_division=1))\n",
    "    print('F1 weighted score: ', f1_score(y_valid, y_valid_pred, average='weighted', zero_division=1))\n",
    "    \n",
    "    return fclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e4284e-170c-4103-a4b0-56f1d2e118a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params  {'max_iter': 5000}\n",
      "Classification report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.54      0.36       509\n",
      "           1       0.25      0.55      0.34      1771\n",
      "           2       0.92      0.64      0.76     17369\n",
      "           3       0.35      0.57      0.43      3065\n",
      "           4       0.31      0.59      0.40       697\n",
      "\n",
      "    accuracy                           0.62     23411\n",
      "   macro avg       0.42      0.58      0.46     23411\n",
      "weighted avg       0.76      0.62      0.66     23411\n",
      "\n",
      "Accuracy score:  0.622058006919824\n",
      "F1 macro score:  0.45923272517222635\n",
      "F1 weighted score:  0.5806831077750069\n",
      "best params  {'max_iter': 100}\n",
      "Classification report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.53      0.15       173\n",
      "           1       0.09      0.49      0.16       751\n",
      "           2       0.96      0.58      0.72     20151\n",
      "           3       0.22      0.54      0.31      1973\n",
      "           4       0.16      0.60      0.25       363\n",
      "\n",
      "    accuracy                           0.57     23411\n",
      "   macro avg       0.30      0.55      0.32     23411\n",
      "weighted avg       0.85      0.57      0.66     23411\n",
      "\n",
      "Accuracy score:  0.5734483789671522\n",
      "F1 macro score:  0.3196159058697913\n",
      "F1 weighted score:  0.48857967100260524\n",
      "best params  {'max_iter': 1000}\n",
      "Classification report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.50      0.40       681\n",
      "           1       0.33      0.58      0.42      2247\n",
      "           2       0.90      0.67      0.77     16302\n",
      "           3       0.40      0.60      0.48      3257\n",
      "           4       0.37      0.54      0.44       924\n",
      "\n",
      "    accuracy                           0.64     23411\n",
      "   macro avg       0.47      0.58      0.50     23411\n",
      "weighted avg       0.74      0.64      0.67     23411\n",
      "\n",
      "Accuracy score:  0.6446115074110461\n",
      "F1 macro score:  0.5028169125790729\n",
      "F1 weighted score:  0.6155688341207731\n",
      "best params  {'max_iter': 1000}\n",
      "Classification report                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.65      0.19       176\n",
      "           1       0.06      0.52      0.11       488\n",
      "           2       0.97      0.56      0.71     20997\n",
      "           3       0.17      0.57      0.26      1448\n",
      "           4       0.14      0.63      0.23       302\n",
      "\n",
      "    accuracy                           0.56     23411\n",
      "   macro avg       0.29      0.59      0.30     23411\n",
      "weighted avg       0.89      0.56      0.66     23411\n",
      "\n",
      "Accuracy score:  0.5638375122805519\n",
      "F1 macro score:  0.30194575609331176\n",
      "F1 weighted score:  0.46571594929798227\n"
     ]
    }
   ],
   "source": [
    "uni_clf = train_and_show_scores(uni_X, y_train, 'Unigram Counts')\n",
    "uni_tf_clf = train_and_show_scores(uni_tf_X, y_train, 'Unigram Tf-Idf')\n",
    "bi_clf = train_and_show_scores(bi_X, y_train, 'Bigram Counts')\n",
    "bi_tf_clf = train_and_show_scores(bi_tf_X, y_train, 'Bigram Tf-Idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242985bc-a6f9-4d27-b60e-00e02dd052fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf = bi_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b9ca3-2043-44dd-9eef-ea4c7992bea6",
   "metadata": {},
   "source": [
    "### Create your Predictions in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8651c86-2f08-4a6c-90ad-9f19e5633baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = final_clf.predict(bi_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27298f-921f-43c4-9b7b-c0cb0c654252",
   "metadata": {},
   "source": [
    "### Perform the final evaluation of the Performance of your model in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802461b2-815d-4291-9d24-5aabf4357acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6871769680919226\n",
      "F1 macro score:  0.5791748046387871\n",
      "F1 weighted score:  0.6687180580434668\n"
     ]
    }
   ],
   "source": [
    "    print('Accuracy score: ', accuracy_score(y_test, y_test_pred))\n",
    "    print('F1 macro score: ', f1_score(y_test, y_test_pred, average='macro', zero_division=1))\n",
    "    print('F1 weighted score: ', f1_score(y_test, y_test_pred, average='weighted', zero_division=1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
